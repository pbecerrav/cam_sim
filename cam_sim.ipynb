{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1659ef-32fc-4ac4-a616-a2e07b9984b7",
   "metadata": {},
   "source": [
    "### Camera Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6fa2d-09f7-481f-a0b8-a4585b87bb38",
   "metadata": {},
   "source": [
    "This is a first stab at a camera simulator using python. ChatGPT was used for reference and Q&A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b4f6b",
   "metadata": {},
   "source": [
    "Import necessary libraries first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f016e-19cb-4e28-98f4-5a8441e05d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install imageio\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RectBivariateSpline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c5eb9",
   "metadata": {},
   "source": [
    "Define the parameters of the images and/or sensor that will be used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 2048\n",
    "image_height = 2048\n",
    "exposure_time = 10  # Exposure time in seconds (?)\n",
    "scene_type = \"Simple SpecRad\" # choose scene option\n",
    "mean_luminance = 100 # cd/m2. Used only for scene 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Noise Functions\n",
    "\n",
    "# Simulate photon shot noise\n",
    "def simulate_photon_noise(image, exposure_time):\n",
    "    \"\"\"\n",
    "    Simulates photon shot noise. This noise is inherent to the randomness of photon arrivals.\n",
    "    :param image: The initial image data (electron counts).\n",
    "    :return: Simulated image data with added photon noise.\n",
    "    \"\"\"\n",
    "    scaled_image = image * exposure_time\n",
    "    poisson_noise = np.random.poisson(scaled_image) / exposure_time\n",
    "    return np.clip(poisson_noise, 0, 255)  # Clip values to [0, 255]\n",
    "\n",
    "# Simulate read noise\n",
    "def simulate_read_noise(image, read_noise_std):\n",
    "    \"\"\"\n",
    "    Simulates read noise. This noise is introduced during the readout process of the sensor.\n",
    "    :param image: The image data (electron counts) before read noise.\n",
    "    :param read_noise_std: Standard deviation of the read noise.\n",
    "    :return: Simulated image data with added read noise.\n",
    "    \"\"\"\n",
    "    noisy_image = image + np.random.normal(0, read_noise_std, image.shape)\n",
    "    return np.clip(noisy_image, 0, 255)  # Clip values to [0, 255]\n",
    "\n",
    "# Simulate dark current noise\n",
    "def simulate_dark_current(image, dark_current_rate, exposure_time):\n",
    "    \"\"\"\n",
    "    Simulates dark current noise. Dark current is generated by the sensor even in the absence of light.\n",
    "    :param image: The image data (electron counts) before dark current noise.\n",
    "    :param dark_current_rate: Dark current rate in electrons per second per pixel.\n",
    "    :param exposure_time: Exposure time in seconds.\n",
    "    :return: Simulated image data with added dark current noise.\n",
    "    \"\"\"\n",
    "    dark_noise = np.random.poisson(dark_current_rate * exposure_time, image.shape)\n",
    "    noisy_image = image + dark_noise\n",
    "    return np.clip(noisy_image, 0, 255)  # Clip values to [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate CMOS camera\n",
    "\n",
    "def simulate_cmos_camera(scene, exposure_time, read_noise_std, dark_current_rate):\n",
    "    \"\"\"\n",
    "    Simulates the behavior of a CMOS camera sensor.\n",
    "    :param scene: The input scene (e.g., a grayscale image).\n",
    "    :param exposure_time: Exposure time in seconds.\n",
    "    :param read_noise_std: Standard deviation of read noise.\n",
    "    :param dark_current_rate: Dark current rate in electrons per second per pixel.\n",
    "    :return: Simulated camera sensor output with photon noise, read noise, and dark current noise.\n",
    "    \"\"\"\n",
    "    sensor_response = scene * exposure_time  # Apply exposure time\n",
    "    sensor_response = simulate_photon_noise(sensor_response, exposure_time)  # Simulate photon shot noise\n",
    "    sensor_response = simulate_read_noise(sensor_response, read_noise_std)  # Simulate read noise\n",
    "    sensor_response = simulate_dark_current(sensor_response, dark_current_rate, exposure_time)  # Simulate dark current\n",
    "    return sensor_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d35043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene simulation\n",
    "\n",
    "if scene_type == '2D Gauss':\n",
    "    # Create a structured scene with a 2D Gaussian distribution\n",
    "    x, y = np.meshgrid(np.linspace(0, 1, image_width), np.linspace(0, 1, image_height))\n",
    "    center_x, center_y = 0.5, 0.5  # Center of the Gaussian distribution\n",
    "    std_x, std_y = 0.2, 0.2  # Standard deviation for the Gaussian distribution\n",
    "    scene = np.exp(-((x - center_x) ** 2 / (2 * std_x ** 2) + (y - center_y) ** 2 / (2 * std_y ** 2)))\n",
    "\n",
    "elif scene_type == \"Simple SpecRad\":\n",
    "    # Wavelengths (in nanometers)\n",
    "    wavelengths = np.linspace(400, 700, image_width)  # Adjust the range as needed\n",
    "\n",
    "    # Create a spectral radiance distribution for the scene\n",
    "    spectral_radiance = np.zeros((image_height, image_width))\n",
    "\n",
    "    # Define a radiance pattern across wavelengths (e.g., a Gaussian distribution)\n",
    "    # Adjust this pattern as needed to match your scene\n",
    "    for i, wavelength in enumerate(wavelengths):\n",
    "        spectral_radiance[:, i] = np.exp(-((wavelength - 550) ** 2 / (2 * 30 ** 2)))\n",
    "\n",
    "    # Normalize the spectral radiance to your desired units\n",
    "    # For this example, let's assume an arbitrary normalization factor\n",
    "    scene = spectral_radiance #* 1e15  # Adjust as needed\n",
    "\n",
    "elif scene_type == \"Macbeth\":\n",
    "    # Define the spectral reflectance values for the Macbeth Color Checker\n",
    "    # These values are typically available in standard data files\n",
    "    # For simplicity, I'll use some example reflectance values\n",
    "    reflectance_data = np.array([\n",
    "        [0.02, 0.04, 0.06, 0.08, 0.10, 0.12],\n",
    "        [0.14, 0.16, 0.18, 0.20, 0.22, 0.24],\n",
    "        [0.26, 0.28, 0.30, 0.32, 0.34, 0.36],\n",
    "        [0.38, 0.40, 0.42, 0.44, 0.46, 0.48]\n",
    "    ])\n",
    "\n",
    "# Define the spectral distribution of the D65 illuminant (in this case, a simplified version)\n",
    "    wavelengths = np.linspace(380, 730, reflectance_data.shape[1])  # Wavelength range (nm)\n",
    "    d65_illuminant = np.array([\n",
    "        [94.81, 104.80, 105.97, 96.16, 113.45, 125.40],\n",
    "        [132.10, 134.19, 131.43, 123.91, 113.42, 109.83],\n",
    "        [107.21, 104.87, 103.17, 101.48, 100.00, 98.93],\n",
    "        [98.05, 97.33, 96.73, 96.19, 95.70, 95.22]\n",
    "    ])\n",
    "\n",
    "    # Calculate the spectral radiance of the scene using the reflectance data and illuminant\n",
    "    spectral_radiance = reflectance_data * d65_illuminant\n",
    "\n",
    "    # Create interpolation functions for wavelength and reflectance\n",
    "    interp_wavelength = RectBivariateSpline(np.arange(spectral_radiance.shape[0]), np.arange(spectral_radiance.shape[1]), wavelengths)\n",
    "    interp_reflectance = RectBivariateSpline(np.arange(spectral_radiance.shape[0]), np.arange(spectral_radiance.shape[1]), reflectance_data)\n",
    "\n",
    "    # Define the new dimensions\n",
    "    x_new = np.linspace(0, spectral_radiance.shape[0] - 1, image_height)\n",
    "    y_new = np.linspace(0, spectral_radiance.shape[1] - 1, image_width)\n",
    "\n",
    "    # Perform the interpolation\n",
    "    wavelengths_new = interp_wavelength(x_new, y_new)\n",
    "    reflectance_new = interp_reflectance(x_new, y_new)\n",
    "\n",
    "    # Calculate the spectral radiance for the new dimensions\n",
    "    spectral_radiance_new = reflectance_new * wavelengths_new\n",
    "\n",
    "    # Scale the spectral radiance to achieve the desired mean luminance\n",
    "    scale_factor = mean_luminance / np.mean(spectral_radiance_new)\n",
    "    scene = spectral_radiance_new * scale_factor\n",
    "\n",
    "else:\n",
    "    print(\"Invalid scene type provided\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate camera response and display output\n",
    "\n",
    "# Simulate CMOS camera response with proper scaling\n",
    "camera_output = simulate_cmos_camera(scene, exposure_time=exposure_time, read_noise_std=0.0005, dark_current_rate=0.001)\n",
    "\n",
    "# Linearly rescale the camera output to the [0, 255] range\n",
    "min_value = np.min(camera_output)\n",
    "max_value = np.max(camera_output)\n",
    "camera_output = 255 * (camera_output - min_value) / (max_value - min_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the scene and camera output (Only run if Scene 1 is used)\n",
    "if scene_type == '2D Gauss':\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Scene\")\n",
    "    plt.imshow(scene, cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Camera Output\")\n",
    "    plt.imshow(camera_output, cmap='gray')\n",
    "\n",
    "elif scene_type == \"Simple SpecRad\":\n",
    "    # Display the scene and camera output (Only run if Scene 2 is used)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Spectral Radiance (550 nm)\")\n",
    "    plt.plot(wavelengths, scene[image_height // 2, :])\n",
    "    plt.xlabel(\"Wavelength (nm)\")\n",
    "    plt.ylabel(\"Spectral Radiance (photons/sec/nm/sr/m²)\")\n",
    "\n",
    "    #plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Scene\")\n",
    "    plt.imshow(scene, cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Camera Output\")\n",
    "    plt.imshow(camera_output, cmap='gray')\n",
    "\n",
    "elif scene_type == \"Macbeth\":\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Spectral Radiance (550 nm)\")\n",
    "    plt.plot(wavelengths, scene[1, :])  # Display the radiance of the second color patch\n",
    "    plt.xlabel(\"Wavelength (nm)\")\n",
    "    plt.ylabel(\"Spectral Radiance (photons/sec/nm/sr/m²)\")\n",
    "\n",
    "    #plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Scene\")\n",
    "    plt.imshow(scene, cmap='gray')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Camera Output\")\n",
    "    plt.imshow(camera_output, cmap='gray')\n",
    "\n",
    "else:\n",
    "    print(\"Invalid scene type provided\") \n",
    "\n",
    "plt.show()\n",
    "\n",
    "scene_mean = np.mean(scene)\n",
    "camera_output_mean = np.mean(camera_output)\n",
    "print(scene_mean, camera_output_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e982190",
   "metadata": {},
   "source": [
    "### Trying EMVA Camera Simulator (based on Algolux tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e9776",
   "metadata": {},
   "source": [
    "1. Import sample png image: This image will form the basis of the \"scene\" simulation. I.e., imagine this image is the \"scene\" captured by the camera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f173194",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imageio.imread(\"M2_Picture_Colorized_50ms.png\")\n",
    "h, w = img.shape[:-1]\n",
    "plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d038be",
   "metadata": {},
   "source": [
    "2. Simulate the radiance spectrum of the image: As this image is simulated a real-world scene, we want to get a simulation of the radiance (or reflectance) spectrum of this scene. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89759ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak Wavelength values for R, G, and B\n",
    "\n",
    "r,g,b = (700,530,440)\n",
    "\n",
    "# Consider wavelengths from 400 nm to 800 nm\n",
    "\n",
    "dom = np.linspace(400, 800, 100)\n",
    "\n",
    "# Build nromal distributions centered around each peak wavelength\n",
    "\n",
    "sig = 200\n",
    "red = 1/(2*np.pi*sig) * np.exp(-((dom-r)**2)/(2*sig))\n",
    "green = 1/(2*np.pi*sig) * np.exp(-((dom-g)**2)/(2*sig))\n",
    "blue = 1/(2*np.pi*sig) * np.exp(-((dom-b)**2)/(2*sig))\n",
    "\n",
    "# Normalise values\n",
    "\n",
    "red /= np.max(red)\n",
    "green /= np.max(green)\n",
    "blue /= np.max(blue)\n",
    "\n",
    "# Multiply each channel of each pixel with its corresponding photon distribution and sum up the channels\n",
    "\n",
    "spectrum = np.einsum('ij,k->ijk', img[:, :, 0].astype(float), red) + \\\n",
    "            np.einsum('ij,k->ijk', img[:, :, 1].astype(float), green) + \\\n",
    "            np.einsum('ij,k->ijk', img[:, :, 2].astype(float), blue)\n",
    "\n",
    "plt.plot(dom, red, 'r')\n",
    "plt.plot(dom, green, 'g')\n",
    "plt.plot(dom, blue, 'b')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4640c",
   "metadata": {},
   "source": [
    "3. Transform the pixels: The plot below simply visualizes the simulated spectrum of a single pixel of the scene. This is of course an approximation, as the real spectrum would be continuous and noisier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise result of the transformation\n",
    "\n",
    "print('pixel (100,100): , r: %s, g: %s, b: %s' % (img[100,100,0], img[100,100,1], img[100,100,2]))\n",
    "plt.plot(dom,spectrum[100,100,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70669e52",
   "metadata": {},
   "source": [
    "4. EMVA1288 Camera Simulator\n",
    "\n",
    "The camera simulator is contained in the Camera class of the emva1288 library (https://emva1288.readthedocs.io/en/latest/_modules/emva1288/camera/camera.html#Camera). This class allows one to simulate any camera by tuning the parameters of the class (e.g. f_number or qe), if one knows them for the camera one wishes to simulate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm width and height of image\n",
    "\n",
    "print(h,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import emva1288 library and necessary classes\n",
    "\n",
    "from emva1288.camera import Camera\n",
    "from emva1288.camera.routines import Qe, get_bayer_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the Bayer filter method to simulate a Bayer filter on top of the simulated sensor of the camera, and then calculate the corresponding QE with the Qe method, after which the results can be provided to the Camera class to simulate the response. \n",
    "\n",
    "The default Camera class already includes pre-defined parameters, which can be adjusted.\n",
    "\n",
    "Below is an example with the default parameters of the Camera class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bayer filter\n",
    "filt = get_bayer_filter(450, 550, 550, 700, w, h, dom)\n",
    "\n",
    "# Create QE object based on filter and image size\n",
    "qe = Qe(filter = filt, width = w, height = h)\n",
    "\n",
    "#### ran into issues with the above routine when w or h were odd numbers ####\n",
    "\n",
    "# Initialise camera\n",
    "cam = Camera(qe = qe, f_number = 8,\n",
    "    pixel_area = 30.25,  # um^2\n",
    "    bit_depth = 8,\n",
    "    width = w,\n",
    "    height = h,\n",
    "    temperature = 25,\n",
    "    exposure = 50000, # in ns (I think this is wrong. It is actually in microseconds)\n",
    "    K = 0.024,\n",
    "    blackoffset = 16315, # This is the blacklevel, which for the CMV4000 can be on the order of 16000\n",
    "    dark_signal_0 = 548.7,\n",
    "    u_esat = 13937,\n",
    "    )\n",
    "\n",
    "# Plot QE for each pixel type (R, G or B)\n",
    "plt.plot(dom, qe.qe[0,0], 'b')\n",
    "plt.plot(dom, qe.qe[1,0], 'g')\n",
    "plt.plot(dom, qe.qe[1,1], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Filter shape:\", filt.shape)\n",
    "#print(\"Qe shape:\", qe._qe.shape)\n",
    "#print(\"Spectrum shape:\", spectrum.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above, the pixel values as seen by the Camera is already simulated in \"cam\". The grab method generates the simulated image using the EMVA1288 parameters and a normal distribution for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_radiance_for to get a reasonable number of photons that hit the sensor\n",
    "factor = np.mean(cam.get_radiance_for(255))/np.mean(spectrum)\n",
    "\n",
    "# Generate simulated image and display it\n",
    "cap = cam.grab(factor * spectrum)\n",
    "plt.imshow(cap, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above simulated image is still \"Bayerised\" (because we added a Bayer filter). We can see the Bayer pattern if we zoom in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in\n",
    "\n",
    "plt.imshow(cap[:100,:100],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, OpenCV can be used to De-bayerise the image and get the full colour image of the scene as the \"camera\" would see it (remember that this is the default Camera from the emva1288 library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "# Debayerise the simulated image\n",
    "colour1 = cv2.cvtColor(cap, cv2.COLOR_BAYER_BG2BGR)\n",
    "plt.imshow(colour1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we can try and make a custom camera with e.g. the AMS CMV4000 sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMV4000 Simulated Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Camera simulator init method.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        f_number : float, optional\n",
    "                   The emva1288 f_number for the camera.\n",
    "        pixel_area : float, optional\n",
    "                     The area of one pixel (in um ^ 2)\n",
    "        bit_depth : int, optional\n",
    "                    The number of bits allowed for one pixel value.\n",
    "        width : int, optional\n",
    "                The number of columns in the the image.\n",
    "        height : int, optional\n",
    "                The number of rows in the image.\n",
    "        temperature : float, optional\n",
    "                      The camera's sensor temperature in degrees Celsius.\n",
    "        temperature_ref : float, optional\n",
    "                          The reference temperature (at which the dark current\n",
    "                          is equal to the reference dark current).\n",
    "        temperature_doubling: float, optional\n",
    "                              The doubling temperature (at which the dark\n",
    "                              current is two times the reference dark\n",
    "                              current).\n",
    "        qe : float, optional\n",
    "             Quantum efficiency (between 0 and 1). If None, a simulated\n",
    "             quantum efficiency is choosen with the\n",
    "             :func:`~emva1288.camera.routines.qe` function.\n",
    "        exposure : float, optional\n",
    "                   The camera's exposure time in ns.\n",
    "        exposure_min : float, optional\n",
    "                       The camera's minimal exposure time in ns.\n",
    "        exposure_max : float, optional\n",
    "                       The camera's maximal exposure time in ns.\n",
    "        K : float, optional\n",
    "            The overall system gain (in DN/e^-).\n",
    "        K_min : float, optional\n",
    "                The overall minimal system gain (in DN/e^-).\n",
    "        K_max : float, optional\n",
    "                The overall maximal system gain (in DN/e^-).\n",
    "        K_steps : int, optional\n",
    "                  The number of available intermediate overall system gains\n",
    "                  between K_min and K_max.\n",
    "        blackoffset : float, optional\n",
    "                      The dark signal offset for each pixel (in DN).\n",
    "        blackoffset_min: float, optional\n",
    "                         The minimal dark signal offset for each pixel (in DN).\n",
    "        blackoffset_max : float, optional\n",
    "                          The maximal dark signal offset for each pixel\n",
    "                          (in DN).\n",
    "        blackoffset_steps : int, optional\n",
    "                            The number of available blackoffsets between the\n",
    "                            mimimal and maximal blackoffsets.\n",
    "        dark_current_ref : float, optional\n",
    "                           The reference dark current used for computing the\n",
    "                           total dark current.\n",
    "        dark_signal_0 : float, optional\n",
    "            Mean number of electrons generated by the electronics (offset)\n",
    "        sigma2_dark_0 : float, optional\n",
    "            Variance of electrons generated by the electronics\n",
    "        u_esat : float, optional\n",
    "            Full well capacity\n",
    "        dsnu : np.array, optional\n",
    "               DSNU image in e^-, array with the same shape of the image\n",
    "               that is added to every image.\n",
    "        prnu : np.array, optional\n",
    "               PRNU image in percentages (1 = 100%), array with the same shape\n",
    "               of the image. Every image is multiplied by it.\n",
    "        seed : int, optional\n",
    "               A seed to initialize the random number generator.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# User-provided parameters\n",
    "f_number = 8\n",
    "pixel_area = 30.25  # um^2\n",
    "bit_depth = 8\n",
    "width = 2048\n",
    "height = 2048\n",
    "temperature = 25\n",
    "exposure = 50000  # in ns (I think this is wrong. It is actually in microseconds)\n",
    "K = 0.024\n",
    "blackoffset = 16315 # This is the blacklevel, which for the CMV4000 can be on the order of 16000\n",
    "dark_signal_0 = 548.7\n",
    "#sigma2_dark_0 = \n",
    "u_esat = 13937\n",
    "\n",
    "# Define QE array\n",
    "# Can be the one defined above for an RGGB Bayer pattern, or the one here for a monochrome (with a 50.2% QE at 535 nm, typical of a CMV4000)\n",
    "\n",
    "# Create QE instance with the original gen_qe method\n",
    "qe_instance = Qe(width=width, height=height)\n",
    "\n",
    "# Manually set the desired QE value at 535 nm\n",
    "center_wavelength = 535  # in nm\n",
    "center_index = np.argmin(np.abs(qe_instance.w - center_wavelength))\n",
    "qe_instance.qe[:, :, center_index] = 0.502 # desired QE value at 535 nm\n",
    "\n",
    "\n",
    "# Create Camera instance with user-provided parameters\n",
    "cmv4000_camera = Camera(\n",
    "    f_number=f_number,\n",
    "    pixel_area=pixel_area,\n",
    "    bit_depth=bit_depth,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    temperature=temperature,\n",
    "    qe=qe_instance,\n",
    "    exposure=exposure,\n",
    "    K=K,\n",
    "    blackoffset=blackoffset,\n",
    "    u_esat=u_esat\n",
    ")\n",
    "\n",
    "# Now you can use the custom_camera instance to generate images\n",
    "\n",
    "radiance = factor * spectrum  # Radiance array\n",
    "simulated_image = cmv4000_camera.grab(radiance)\n",
    "plt.imshow(simulated_image, cmap = \"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(simulated_image), np.max(simulated_image), np.min(simulated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(img), np.max(img), np.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in\n",
    "\n",
    "plt.imshow(simulated_image[:100,:100],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debayerise the simulated image if necessary\n",
    "colour2 = cv2.cvtColor(simulated_image, cv2.COLOR_BAYER_BG2BGR)\n",
    "plt.imshow(colour2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
